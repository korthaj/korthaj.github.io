<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Amortized time complexity · YourBasic </title>
  <meta name="description" content="Amortized analysis considers both the cheap and expensive operations performed by an algorithm. It is used for algorithms that have expensive operations that happen only rarely.">
  
  <link rel="stylesheet" href="/style.css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
  <link rel="icon" type="image/png" href="/res/favicon-16x16.png">
  <link rel="icon" type="image/png" href="/res/favicon-32x32.png">
  <link rel="icon" type="image/png" href="/res/favicon-96x96.png">
  

  <script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yourbasic.org/algorithms/amortized-time-complexity-analysis/"
  },
  "headline": "Amortized time complexity",
  "image": [
    "https://yourbasic.org/algorithms/pink-coins.jpg"
   ],
  "datePublished": "2018-04-19T00:00:00&#43;0000",
  "dateModified": "2019-05-13T00:00:00&#43;0000",
  "author": {
    "@type": "Person",
    "name": "Stefan Nilsson"
  },
   "publisher": {
    "@type": "Organization",
    "name": "yourbasic.org",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yourbasic.org/res/favicon-96x96.png"
    }
  },
  "description": "Amortized analysis considers both the cheap and expensive operations performed by an algorithm. It is used for algorithms that have expensive operations that happen only rarely."
}
</script>

<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Amortized time complexity">
<meta property="og:description" content="Amortized analysis considers both the cheap and expensive operations performed by an algorithm. It is used for algorithms that have expensive operations that happen only rarely.">
<meta property="og:url" content="https://yourbasic.org/algorithms/amortized-time-complexity-analysis/">
<meta property="og:image" content="https://yourbasic.org/algorithms/pink-coins.jpg">



</head>

<body>
<header>
  <nav>
    <ul>
      <li><a href="/about/">About</a></li>
      <li><a href="/">Home</a></li>
      <li class="here"><a href="/algorithms/">Algorithms</a></li>
      <li><a href="/golang/">Go</a></li>
    </ul>
  </nav>
</header>

<main>
<article>
<h1>Amortized time complexity</h1>
<div class="tagline">yourbasic.org</div>
<p class="lead">Amortized analysis is used for algo&shy;rithms that have <b>expensive opera&shy;tions</b> that happen only&nbsp;<b>rarely</b>.</p>
<!-- CC0: https://www.pexels.com/photo/money-pink-coins-pig-9660/ -->
<div><img src="/algorithms/pink-coins.jpg"></div>
<p>Amortized complexity analysis is most commonly used with data structures
that have state that persists between operations.
The basic idea is that an expensive operation can alter the state so that
the worst case cannot occur again for a long time, thus amortizing its cost.</p>
<blockquote class="math">
Let T<sub>1</sub>, T<sub>2</sub>,&nbsp;…, T<sub>k</sub> be the complexities
of a sequence of operations on a data structure. The <b>amortized complexity</b>
of a single operation in this sequence is
(T<sub>1</sub>&nbsp;+&nbsp;T<sub>2</sub>&nbsp;+&nbsp;…+&nbsp;T<sub>k</sub>)&nbsp;/&nbsp;k.
</blockquote>
<h2 id="example-a-dynamic-array">Example: a dynamic array</h2>
<p>In a <a href="/algorithms/time-complexity-arrays/">dynamic array</a>,
elements are stored at the start of an underlying fixed array,
and the remaining positions are unused.</p>
<pre><code><span class="comment">// Append x to the end of a dynamic array a.</span>
<b>algorithm</b> append(x, a):
	<b>if</b> a.size == a.capacity
		b ← new array with twice the capacity of a
		copy a into b
		a ← b
	a[a.size] ← x
	a.size++
</code></pre>
<p>Here&rsquo;s a view of the memory when appending the elements 2, 7, 1, 3, 8, 4
to an inititally empty array with capacity 2.</p>
<!-- CC0: https://en.wikipedia.org/wiki/File:Dynamic_array.svg -->
<div><img src="/algorithms/dynamic-array.png" alt="Dynamic array example"></div>
<h3 id="worst-case-time">Worst-case time</h3>
<p>The worst-case time complexity for appending an element
to an array of length <i>n</i>, using this algorithm, is Θ(<i>n</i>).
If the array is full, the algorithm allocates a new array of length 2<i>n</i>,
and then copies the elements from the old array into the new one.</p>
<p>Cleary this result is overly pessimistic.
The following <i>n</i> append operations will be much cheaper –
each of them will run in constant time since the newly allocated array
has room for all the new elements.</p>
<h3 id="amortized-time">Amortized time</h3>
<p>An amortized time analysis gives a much better understanding of the algorithm.</p>
<p>Consider a sequence of <i>n</i> append operations,
where we start with an array of length 1. A careful analysis shows
that the total time of these operations is only Θ(<i>n</i>).</p>
<ul>
<li> There will be a total of <i>n</i> constant-time assignment and increment operations.
</li>
<li> The resizing will happen only at operation 1, 2, 4, …, 2<sup>k</sup>,
  for a total of 1&nbsp;+&nbsp;2&nbsp;+&nbsp;4&nbsp;+&nbsp;…+&nbsp;2<sup>k</sup>&nbsp;=
  2·2<sup>k</sup>&nbsp;-&nbsp;1 constant-time element copy operations.
  Since&nbsp;2<sup>k</sup>&nbsp;&le;&nbsp;<i>n</i>, this is at most&nbsp;2<i>n</i>&nbsp;-&nbsp;1.
</li>
</ul>
<p>Hence, the amortized time complexity for a single append operation is Θ(1).</p>
<h2 id="more-on-algorithm-analysis">More on algorithm analysis</h2>
<div><a href="/algorithms/time-complexity-explained/"><img src="/algorithms/abacus-thumb.jpg" title="Time complexity: Count your steps"></a></div>
<p style="margin-top:0; margin-bottom:2em;"><a href="/algorithms/time-complexity-explained/">Time complexity: Count your steps</a></p>
<div><a href="/algorithms/big-o-notation-explained/"><img src="/algorithms/big-o-thumb.jpg" title="Big O notation"></a></div>
<p style="margin-top:0; margin-bottom:2em;"><a href="/algorithms/big-o-notation-explained/">Big O notation</a></p>


</article>
<aside>

    
  <h2>Related</h2>

  <div class="reference">
    <a href="/algorithms/time-complexity-arrays/">Time complexity of array/list operations [Java, Python]</a>
    <div class="desc">To write fast code, avoid linear-time operations in Java ArrayLists and Python lists. Maps or dictionaries can be efficient alternatives.</div>
    <div class="source">yourbasic.org</div>
  </div>

  <div class="reference">
    <a href="/golang/append-explained/">How to append anything (element, slice or string) to a slice</a>
    <div class="desc">The append function appends elements to the end of a slice: if there is enough capacity, the underlying array is reused; if not, a new underlying array is allocated and the data is copied over.</div>
    <div class="source">yourbasic.org</div>
  </div>

<h2>Most Read</h2>
    <div style="margin-top:1em;"><a href="/algorithms/time-complexity-explained/" title="How to analyse time complexity: Count your steps"><img src="/algorithms/abacus-mini.jpg"></a></div>
  <ul class="none">
  
    <li><a href="/algorithms/time-complexity-explained/">How to analyze time complexity: Count your steps</a></li>

    <li><a href="/algorithms/big-o-notation-explained/">Big O notation: definition and examples</a></li>

    <li><a href="/algorithms/dynamic-programming-explained/">Dynamic programming [step-by-step example]</a></li>

    <li><a href="/algorithms/loop-invariants-explained/">Loop invariants can give you coding superpowers</a></li>

    <li><a href="/algorithms/your-basic-api/">API design: principles and best practices</a></li>

    <li><a href="/algorithms/fastest-sorting-algorithm/">O(n log log n) time integer sorting</a></li>

  </ul>
  <p><a href="/algorithms/"><b>See all 24 algorithm articles</b></a></p>
</aside>
</main>

<footer>
  This work is licensed under&nbsp;a&nbsp;<a rel="license" alt="CC BY 3.0"
  href="http://creativecommons.org/licenses/by/3.0/"><span
  style="font-size:smaller;">CC&nbsp;BY&nbsp;3.0</span>&nbsp;license</a>.
</footer>
</body>
</html>
