<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Big O notation: definition and examples · YourBasic </title>
  <meta name="description" content="Big O notation is a convenient way to describe how fast a function is growing. It is often used in computer science when estimating time complexity.">
  
  <link rel="stylesheet" href="/style.css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,400i,700,700i&amp;subset=latin-ext" rel="stylesheet">
  <link rel="icon" type="image/png" href="/res/favicon-16x16.png">
  <link rel="icon" type="image/png" href="/res/favicon-32x32.png">
  <link rel="icon" type="image/png" href="/res/favicon-96x96.png">
  

  <script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yourbasic.org/algorithms/big-o-notation-explained/"
  },
  "headline": "Big O notation: definition and examples",
  "image": [
    "https://yourbasic.org/algorithms/big-o.jpg"
   ],
  "datePublished": "2018-03-04T00:00:00&#43;0000",
  "dateModified": "2020-06-20T00:00:00&#43;0000",
  "author": {
    "@type": "Person",
    "name": "Stefan Nilsson"
  },
   "publisher": {
    "@type": "Organization",
    "name": "yourbasic.org",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yourbasic.org/res/favicon-96x96.png"
    }
  },
  "description": "Big O notation is a convenient way to describe how fast a function is growing. It is often used in computer science when estimating time complexity."
}
</script>

<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Big O notation: definition and examples">
<meta property="og:description" content="Big O notation is a convenient way to describe how fast a function is growing. It is often used in computer science when estimating time complexity.">
<meta property="og:url" content="https://yourbasic.org/algorithms/big-o-notation-explained/">
<meta property="og:image" content="https://yourbasic.org/algorithms/big-o.jpg">



</head>

<body>
<header>
  <nav>
    <ul>
      <li><a href="/about/">About</a></li>
      <li><a href="/">Home</a></li>
      <li class="here"><a href="/algorithms/">Algorithms</a></li>
      <li><a href="/golang/">Go</a></li>
    </ul>
  </nav>
</header>

<main>
<article>
<h1>Big O notation: definition and examples</h1>
<div class="tagline">yourbasic.org</div>
<p class="lead">Big O notation is a convenient way to describe how fast a function is&nbsp;growing.</p>
<!-- CC BY 2.0: https://commons.wikimedia.org/wiki/File:Ocean_City_Ferris_Wheel.jpg -->
<div><img src="/algorithms/big-o.jpg"></div>
<div style="margin-top: 1em;">
<div style="float: left; min-width: 30%; margin-right: 2em;">
  <ul class="toc" style="margin: 0;">
    <li><a href="#definition">Definition</a></li>
    <li><a href="#constant-time">Constant time</a></li>
    <li><a href="#linear-time">Linear time</a></li>
    <li><a href="#quadratic-time">Quadratic time</a></li>
  </ul>
</div>
<div style="float: left;">
  <ul class="toc" style="margin: 0;">
    <li><a href="#sloppy-notation">Sloppy notation</a></li>
    <li><a href="#ω-and-θ-notation">Ω and Θ notation</a></li>
    <li><a href="#key-takeaways">Key takeaways</a></li>
  </ul>
</div>
</div>
<div style="clear: both"></div>
<h2 id="definition">Definition</h2>
<p>When we compute the <a href="/algorithms/time-complexity-explained/">time complexity</a> T(<i>n</i>)
of an algorithm we rarely get an exact result, just an estimate. That&rsquo;s fine, in computer science we are typically
only interested in how fast T(<i>n</i>) is growing as a function of the input size <i>n</i>.</p>
<p>For example, if an algorithm increments each number in a list of length <i>n</i>,
we might say: &ldquo;This algorithm runs in <i>O</i>(<i>n</i>) time and performs <i>O</i>(1) work for each element&rdquo;.</p>
<p>Here is the formal mathematical definition of Big O.</p>
<blockquote class="math">
Let T(<i>n</i>) and f(<i>n</i>) be two positive functions.
We write <b>T(<i>n</i>)&nbsp;∊&nbsp;<i>O</i>(f(<i>n</i>))</b>, and say that
T(<i>n</i>) has order of&nbsp;f(<i>n</i>),
if there are positive constants M and n₀ such that
T(<i>n</i>)&nbsp;&le;&nbsp;M·f(<i>n</i>) for all&nbsp;<i>n</i>&nbsp;&ge;&nbsp;n₀.
</blockquote>
<p>This graph shows a situation where all of the conditions in the definition are met.</p>
<img style="padding:1em 0 1.5em 0;" src="/algorithms/Ordo.png" alt="Graph of relation between a function T and its limit function f">
<p>In essence:</p>
<blockquote>
T(<i>n</i>)&nbsp;∊&nbsp;<i>O</i>(f(<i>n</i>)) means that
T(<i>n</i>) doesn't grow faster than&nbsp;f(<i>n</i>).
</blockquote>
<h2 id="constant-time">Constant time</h2>
<p>Let&rsquo;s start with the simplest possible example: <strong>T(<i>n</i>) ∊ <i>O</i>(1)</strong>.</p>
<p>According to the definition this means that there are constants M and n₀
such that T(<i>n</i>) ≤ M when
<i>n</i> ≥ n₀.
In other words, T(<i>n</i>) ∊ <i>O</i>(1) means that
T(<i>n</i>) is smaller than some fixed constant, whose value isn&rsquo;t stated,
for all large enough values of <i>n</i>.</p>
<p>An algorithm with T(<i>n</i>) ∊ <i>O</i>(1) is said to have
<strong>constant time complexity</strong>.</p>
<h2 id="linear-time">Linear time</h2>
<p>In the <a href="/algorithms/time-complexity-explained/">Time complexity</a> article,
we looked at an algorithm with complexity
T(<i>n</i>) = <i>n</i> -1.
Using Big O notation this can be written as <strong>T(<i>n</i>) ∊ <i>O</i>(<i>n</i>)</strong>.
(If we choose M = 1 and n₀ = 1, then
T(<i>n</i>) = <i>n</i> - 1
 ≤ 1·<i>n</i> when
<i>n</i> ≥ 1.)</p>
<p>An algorithm with T(<i>n</i>) ∊ <i>O</i>(<i>n</i>) is said to have
<strong>linear time complexity</strong>.</p>
<h2 id="quadratic-time">Quadratic time</h2>
<p>The second algorithm in the
<a href="/algorithms/time-complexity-explained/">Time complexity</a> article
had time complexity T(<i>n</i>) = <i>n</i><sup>2</sup>/2 - <i>n</i>/2.
With Big O notation, this becomes
<strong>T(<i>n</i>) ∊ <i>O</i>(<i>n</i><sup>2</sup>)</strong>, and we say
that the algorithm has <strong>quadratic time complexity</strong>.</p>
<h2 id="sloppy-notation">Sloppy notation</h2>
<p>The notation T(<i>n</i>) ∊ <i>O</i>(f(<i>n</i>)) can be used even when
f(<i>n</i>) grows <strong>much faster</strong> than T(<i>n</i>). For example, we may write
T(<i>n</i>) = <i>n</i> - 1 ∊ <i>O</i>(<i>n</i><sup>2</sup>).
This is indeed true, but not very useful.</p>
<h2 id="ω-and-θ-notation">Ω and Θ notation</h2>
<p><strong>Big Omega</strong> is used to give a <strong>lower bound</strong> for the growth of a function.
It&rsquo;s defined in the same way as Big O, but with the inequality sign turned around:</p>
<blockquote class="math">
Let T(<i>n</i>) and f(<i>n</i>) be two positive functions.
We write <b>T(<i>n</i>)&nbsp;∊&nbsp;&Omega;(f(<i>n</i>))</b>, and say that
T(<i>n</i>) is big omega of&nbsp;f(<i>n</i>),
if there are positive constants m and n₀ such that
T(<i>n</i>)&nbsp;&ge;&nbsp;m(f(<i>n</i>)) for all&nbsp;<i>n</i>&nbsp;&ge;&nbsp;n₀.
</blockquote>
<p><strong>Big Theta</strong> is used to indicate that a function is bounded both from above and below.</p>
<blockquote class="math">
<b>T(<i>n</i>)&nbsp;∊&nbsp;&Theta;(f(<i>n</i>))</b> if
T(<i>n</i>) is both <i>O</i>(f(<i>n</i>)) and &Omega;(f(<i>n</i>)).
</blockquote>
<h3 id="example">Example</h3>
<p>T(<i>n</i>) = 3<i>n</i><sup>3</sup> + 2<i>n</i> + 7 ∊ Θ(<i>n</i><sup>3</sup>)</p>
<ul>
<li>If <i>n</i> ≥ 1, then
T(<i>n</i>) = 3<i>n</i><sup>3</sup> + 2<i>n</i> + 7 ≤
3<i>n</i><sup>3</sup> + 2<i>n</i><sup>3</sup> + 7<i>n</i><sup>3</sup> =
12<i>n</i><sup>3</sup>. Hence T(<i>n</i>) ∊ <i>O</i>(<i>n</i><sup>3</sup>).</li>
<li>On the other hand,
T(<i>n</i>) = 3<i>n</i><sup>3</sup> + 2<i>n</i> + 7 &gt; <i>n</i><sup>3</sup>
for all positive <i>n</i>.
Therefore  T(<i>n</i>) ∊ Ω(<i>n</i><sup>3</sup>).</li>
<li>And consequently  T(<i>n</i>) ∊ Θ(<i>n</i><sup>3</sup>).</li>
</ul>
<h2 id="key-takeaways">Key takeaways</h2>
<p>When analyzing algorithms you often come across the following time complexities.</p>
<table style="max-width:400px;">
  <thead>
    <tr>
      <th>Complexity</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="border-bottom: 0;">&Theta;(1)</td>
      <td style="border-bottom: 0;">Good news</td>
    </tr>
    <tr>
      <td style="border-bottom: 0; padding-top: 0;">&Theta;(log&nbsp;<i>n</i>)</td>
      <td style="border-bottom: 0; padding-top: 0;"></td>
    </tr>
    <tr>
      <td style="border-bottom: 0; padding-top: 0;">&Theta;(<i>n</i>)</td>
      <td style="border-bottom: 0; padding-top: 0;"></td>
    </tr>
    <tr>
      <td style="padding-top: 0;">&Theta;(<i>n</i>&nbsp;log&nbsp;<i>n</i>)</td>
      <td style="padding-top: 0;"></td>
    </tr>
    <tr>
      <td style="border-bottom: 0;">&Theta;(<i>n</i><sup>k</sup>), where k&nbsp;≥&nbsp;2</td>
      <td style="border-bottom: 0;">Bad news</td>
    </tr>
    <tr>
      <td style="border-bottom: 0; padding-top: 0;">&Theta;(k<sup><i>n</i></sup>), where k&nbsp;≥&nbsp;2</td>
      <td style="border-bottom: 0; padding-top: 0;"></td>
    </tr>
    <tr>
      <td style="padding-top: 0;">&Theta;(<i>n</i>!)</td>
      <td style="padding-top: 0;"></td>
    </tr>
  </tbody>
</table>
<h3 id="onlogn-is-really-good"><i>O</i>(<i>n</i> log <i>n</i>) is really good</h3>
<p>The first four complexities indicate an excellent algorithm.
An algorithm with worst-case time complexity
W(<i>n</i>) ∊ <i>O</i>(<i>n</i> log <i>n</i>) scales very well,
since logarithms grow very slowly.</p>
<blockquote>
<ul  class="none">
<li>log<sub>2</sub>&nbsp;1,000&nbsp;&asymp;&nbsp;10</li>
<li>log<sub>2</sub>&nbsp;1,000,000&nbsp;&asymp;&nbsp;20</li>
<li>log<sub>2</sub>&nbsp;1,000,000,000&nbsp;&asymp;&nbsp;30</li>
</blockquote>
<p>In fact, Θ(<i>n</i> log <i>n</i>) time complexity is very close to linear –
it takes roughly twice the time to solve a problem twice as big.</p>
<div><img src="/algorithms/n-vs-nlogn.png" alt="Graph showing n log n growth rate" title="n log n growth rate"></div>
<div style="font-size:smaller;"><i>n</i>&nbsp;log&nbsp;<i>n</i> growth rate is close to linear</div>
<h3 id="ωn2-is-pretty-bad">Ω(<i>n</i><sup>2</sup>) is pretty bad</h3>
<p>The last three complexities typically spell trouble.
Algorithms with time complexity Ω(<i>n</i><sup>2</sup>)
are useful only for small input: <i>n</i> shouldn&rsquo;t be more than a few thousand.</p>
<blockquote>
<p>10,000<sup>2</sup> = 100,000,000</p></blockquote>
<p>An algorithm with quadratic time complexity scales poorly –
if you increase the input size by a factor 10,
the time increases by a factor 100.</p>
<h3 id="further-reading">Further reading</h3>
<div><a href="/algorithms/time-complexity-arrays/"><img src="/algorithms/scooter-vs-taxi-thumb.jpeg" title="Time complexity of array/list operations [Java, Python]"></a></div>
<p style="margin-top:0; margin-bottom:2em;"><a href="/algorithms/time-complexity-arrays/">Time complexity of array/list operations [Java, Python]</a></p>


</article>
<aside>

    
  <h2>Related</h2>

  <div class="reference">
    <a href="https://en.wikipedia.org/wiki/Big_O_notation">Big O notation</a>
    <div class="source">Wikipedia</div>
    <div class="author"></div>
  </div>

  <div class="reference">
    <a href="/algorithms/time-complexity-explained/">How to analyze time complexity: Count your steps</a>
    <div class="desc">Time complexity analysis esti­mates the time to run an algo­rithm. It&#39;s calcu­lated by counting elemen­tary opera­tions.</div>
    <div class="source">yourbasic.org</div>
  </div>

  <div class="reference">
    <a href="/algorithms/time-complexity-recursive-functions/">Time complexity of recursive functions [Master theorem]</a>
    <div class="desc">You can often compute the time complexity of a recursive function by solving a recurrence relation. The master theorem gives solutions to a class of common recurrences.</div>
    <div class="source">yourbasic.org</div>
  </div>

<h2>Most Read</h2>
    <div style="margin-top:1em;"><a href="/algorithms/time-complexity-explained/" title="How to analyse time complexity: Count your steps"><img src="/algorithms/abacus-mini.jpg"></a></div>
  <ul class="none">
  
    <li><a href="/algorithms/time-complexity-explained/">How to analyze time complexity: Count your steps</a></li>

    <li><a href="/algorithms/big-o-notation-explained/">Big O notation: definition and examples</a></li>

    <li><a href="/algorithms/dynamic-programming-explained/">Dynamic programming [step-by-step example]</a></li>

    <li><a href="/algorithms/loop-invariants-explained/">Loop invariants can give you coding superpowers</a></li>

    <li><a href="/algorithms/your-basic-api/">API design: principles and best practices</a></li>

    <li><a href="/algorithms/fastest-sorting-algorithm/">O(n log log n) time integer sorting</a></li>

  </ul>
  <p><a href="/algorithms/"><b>See all 24 algorithm articles</b></a></p>
</aside>
</main>

<footer>
  This work is licensed under&nbsp;a&nbsp;<a rel="license" alt="CC BY 3.0"
  href="http://creativecommons.org/licenses/by/3.0/"><span
  style="font-size:smaller;">CC&nbsp;BY&nbsp;3.0</span>&nbsp;license</a>.
</footer>
</body>
</html>
